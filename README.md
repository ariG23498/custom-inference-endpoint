# text-encoder-ie
Deploying an LLM and exposing a custom function using Inference Endpoints
